<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>[Notes] 常用命令</title>
    <link href="/2021/07/04/note-command/"/>
    <url>/2021/07/04/note-command/</url>
    
    <content type="html"><![CDATA[<p>常用命令 of Linux, Redis, Vim, Git, SSH and MarkDown</p><span id="more"></span><h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><ul><li>查看PCI-E插槽使用情况：dmidecode | grep -1 PCI</li><li>查看显卡信息：lspci | grep -i vga</li></ul><ul><li>复制粘贴文件：　　cp  [选项]  源文件或目录  目标文件或目录</li><li>剪切粘贴文件：　　mv  [选项]  源文件或目录  目标文件或目录</li></ul><ul><li>创建文件夹： mkdir</li><li>删除文件：rm -rf 文件名   <ul><li>//-r 就是向下递归，不管有多少级目录，一并删除</li><li>//-f 就是直接强行删除，不作任何提示的意思）</li></ul></li><li>查看文件系统： df</li></ul><ul><li><p>压缩：tar -zcvf archive_name.tar.gz filename</p></li><li><p>解压缩：</p><ul><li>tar -zxvf archive_name.tar.gz (-C new_dir)</li><li>unzip zipped_file.zip (-d unzipped_directory)</li></ul></li></ul><ul><li><p>复制文件：</p><ul><li>cp dir1/a.doc dir2  表示将dir1下的a.doc文件复制到dir2目录下</li><li>cp -r dir1 dir2     表示将dir1及其dir1下所包含的文件复制到dir2下</li><li>cp -r dir1/. dir2   表示将dir1下的文件复制到dir2,不包括dir1目录</li></ul></li></ul><ul><li>修改kernel配置参数：<ul><li>目录：cd proc/sys/kernel</li><li>修改：echo value &gt;修改项（不能使用vim，vim需要copy一份修改后在覆盖，权限不够）</li></ul></li></ul><ul><li>查看各用户占用空间：sudo du -sh /home/*</li></ul><hr><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><ul><li>获取redis中所有的key：  redis 127.0.0.1:6379&gt; KEYS *</li><li>删除数据库所有数据：FLUSHALL</li><li>redis-server  直接启动</li><li>redis-server  配置路径  如redis-server  /etc/redis.conf<br>这时候要后台启动的话就需要配置redis.conf中的daemonize no改为yes</li><li>停止   redis-cli (-a 密码) -h 127.0.0.1 -p 6379 shutdown</li><li>确认是否启动，使用  ps -ef|grep redis</li><li>查看结点状态：INFO</li><li>查看集群状态：CLUSTER INFO</li><li>查看集群的槽：cluster slots</li><li>redis集群，添加新节点：CLUSTER MEET 127.0.0.1 7002</li><li>Redis清空数据库：flushall</li></ul><hr><h3 id="Vim"><a href="#Vim" class="headerlink" title="Vim"></a>Vim</h3><ul><li><p>有三个快捷键可以进入编辑模式，a i o</p></li><li><p>保存并退出，输入:wq</p></li><li><p>查找字符串，输入/或者？加需要查找的字符串，查看下一个，小写n，跳转到上一个，大写N</p></li><li><p>[Ctrl] + [f]    屏幕『向下』移动一页，相当于 [Page Down]按键<br>[Ctrl] + [b]    屏幕『向上』移动一页，相当于 [Page Up] 按键</p></li><li><p>:num   直接跳到第num行。</p></li><li><p>多行注释：</p><ol><li><p>进入命令行模式，按ctrl + v进入 visual block模式，然后按j, 或者k选中多行，把需要注释的行标记起来</p></li><li><p>按大写字母I，再插入注释符，例如//</p></li><li><p>按esc键就会全部注释了</p></li></ol></li><li><p>取消多行注释：</p><ol><li>进入命令行模式，按ctrl + v进入 visual block模式，按字母l横向选中列的个数，例如 // 需要选中2列</li><li>按字母j，或者k选中注释符号</li><li>按d键就可全部取消注释</li></ol></li><li><p>定位到文件尾：G</p></li></ul><hr><h3 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h3><ul><li>初始化：git init</li><li>添加到github远程仓库：git remote add origin 仓库链接</li><li>下载代码：git clone URL</li><li>查看分支：git branch （-a 查看所有分支）</li><li>切换分支：git checkout 分支名</li><li>如果我们修改了本地的某个文件但是没有提交，这时我们用 $ git status可以看到提示</li><li>批量提交修改：git add –all</li><li>拉取：git pull</li><li>上传：git push origin master</li></ul><hr><h3 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h3><p>在终端连接ssh的断开关闭退出的方法</p><ol><li>输入logout    比较正式的退出方式</li><li>输入exit        等同于方法1</li><li>Ctrl + D        等同于方法1，方便快捷</li></ol><hr><h3 id="MarkDown"><a href="#MarkDown" class="headerlink" title="MarkDown"></a>MarkDown</h3><ul><li>上下标：</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++">H&lt;sub&gt;<span class="hljs-number">2</span>&lt;/sub&gt;O  CO&lt;sub&gt;<span class="hljs-number">2</span>&lt;/sub&gt;<br>爆米&lt;sup&gt;TM&lt;/sup&gt;<br></code></pre></td></tr></table></figure><p>显示效果为：H<sub>2</sub>O    CO<sub>2</sub>    爆米<sup>TM</sup></p><ul><li>显示空行：&amp;nbsp;</li></ul>]]></content>
    
    
    <categories>
      
      <category>Notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Command</tag>
      
      <tag>Linux</tag>
      
      <tag>Vim</tag>
      
      <tag>Git</tag>
      
      <tag>SSH</tag>
      
      <tag>Redis</tag>
      
      <tag>MarkDown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[Tutorial] Pycharm+PyQt5</title>
    <link href="/2021/07/04/Pycharm-PyQt5/"/>
    <url>/2021/07/04/Pycharm-PyQt5/</url>
    
    <content type="html"><![CDATA[<h4 id="Pycharm-amp-PyQt5-环境搭建记录"><a href="#Pycharm-amp-PyQt5-环境搭建记录" class="headerlink" title="Pycharm &amp; PyQt5 环境搭建记录"></a>Pycharm &amp; PyQt5 环境搭建记录</h4><span id="more"></span><h5 id="Step1：环境搭建"><a href="#Step1：环境搭建" class="headerlink" title="Step1：环境搭建"></a>Step1：环境搭建</h5><ul><li><p>过程参考：</p><p><a href="https://www.jb51.net/article/162137.htm">https://www.jb51.net/article/162137.htm</a></p><p><a href="https://blog.csdn.net/px41834/article/details/79383985">https://blog.csdn.net/px41834/article/details/79383985</a></p></li><li><p>主要问题：</p><ol><li><p>designer.exe路径问题：</p><p>designer的路径可能并不是..\venv\Lib\site-packages\pyqt5-tools\designer.exe，建议使用Everything直接搜索designer.exe，有可能位于..\venv\Lib\site-packages\qt5_applications\Qt\bin</p></li><li><p>无法启动qtdesigner：</p><p><img src="/img/article/Tutorial/20200616112822349.png"></p><p>添加环境变量，参考<a href="http://www.xiaoheidiannao.com/15127.html">http://www.xiaoheidiannao.com/15127.html</a></p><p>变量名：QT_QPA_PLATFORM_PLUGIN_PATH</p><p>变量值：与designer同级的plugins文件夹路径</p></li></ol></li></ul><h5 id="Step2：designer入门"><a href="#Step2：designer入门" class="headerlink" title="Step2：designer入门"></a>Step2：designer入门</h5><ul><li><p>参考：</p><p><a href="https://blog.csdn.net/azuremouse/article/details/90338961">https://blog.csdn.net/azuremouse/article/details/90338961</a></p><p><a href="https://blog.csdn.net/yl_best/article/details/83825223">https://blog.csdn.net/yl_best/article/details/83825223</a></p></li></ul><h5 id="Step3：Table-View入门"><a href="#Step3：Table-View入门" class="headerlink" title="Step3：Table View入门"></a>Step3：Table View入门</h5><ul><li>参考：<a href="https://blog.csdn.net/jia666666/article/details/81624259">https://blog.csdn.net/jia666666/article/details/81624259</a></li></ul><h5 id="Step4：生成可执行文件"><a href="#Step4：生成可执行文件" class="headerlink" title="Step4：生成可执行文件"></a>Step4：生成可执行文件</h5><ul><li>参考：<a href="https://blog.csdn.net/qq_32939413/article/details/86564611">https://blog.csdn.net/qq_32939413/article/details/86564611</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Tutorial</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>Qt</tag>
      
      <tag>GUI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[Redis] Redis持久化机制的源码分析</title>
    <link href="/2021/07/04/Redis-code/"/>
    <url>/2021/07/04/Redis-code/</url>
    
    <content type="html"><![CDATA[<p>文章基于Redis-4.0版本，介绍AOF持久化策略的具体实现过程，包括AOF持久化的触发，文件追加、写入、同步的代码实现，启动阶段的数据还原实现，AOF重写的触发与实现等。</p><span id="more"></span><hr><h3 id="1-AOF持久化"><a href="#1-AOF持久化" class="headerlink" title="1 AOF持久化"></a>1 AOF持久化</h3><h4 id="1-1-AOF触发"><a href="#1-1-AOF触发" class="headerlink" title="1.1 AOF触发"></a>1.1 AOF触发</h4><p>Redis执行命令时都会先建立一个客户端，然后由客户端去和服务器连接， redis的命令执行中有一个核心部分，就是call()方法，call函数声明如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* src/server.c/call() */</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">call</span><span class="hljs-params">(client *c, <span class="hljs-keyword">int</span> flags)</span></span><br></code></pre></td></tr></table></figure><p>其中client代表客户端，flags是一个特殊标识，当flags为CLIENT_FORCE_AOF时，标志着强制服务器将当前执行的命令写入到AOF文件当中。除此之外，在call函数执行过程中还维护着一个变量dirty用来标识当前执行的命令操作是否改变服务器数据，如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c">dirty = server.dirty;  <br>c-&gt;cmd-&gt;proc(c);  <span class="hljs-comment">//实际的命令执行函数</span><br>dirty = server.dirty-dirty;  <br><span class="hljs-keyword">if</span> (dirty &lt; <span class="hljs-number">0</span>) dirty = <span class="hljs-number">0</span>;  <br></code></pre></td></tr></table></figure><p>通过以上两个判断条件，就可以设置命令传播的标识，进而调用传播方法：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">if</span> (dirty)   propagate_flags |= (PROPAGATE_AOF|PROPAGATE_REPL);  <br><span class="hljs-keyword">if</span> (c-&gt;flags &amp; CLIENT_FORCE_AOF)   propagate_flags |= PROPAGATE_AOF;  <br> <br><span class="hljs-comment">//Call propagate only if at least one of AOF/REPL propagation is needed</span><br><span class="hljs-keyword">if</span> (propagate_flags != PROPAGATE_NONE &amp;&amp; !(c-&gt;cmd-&gt;flags &amp; CMD_MODULE))  <br>    propagate(c-&gt;cmd,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc,propagate_flags);  <br></code></pre></td></tr></table></figure><h4 id="1-2-文件追加、写入、同步"><a href="#1-2-文件追加、写入、同步" class="headerlink" title="1.2 文件追加、写入、同步"></a>1.2 文件追加、写入、同步</h4><p>propagate()函数的作用是将命令传播给AOF以及slave中（slave是Redis集群部分的内容），propagate()将命令传播到AOF中是通过调用feedAppendOnlyFile()函数实现的，在调用该函数之前，首先需要检查AOF机制是否已开启：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* src/server.c/propagate() */</span>  <br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">propagate</span><span class="hljs-params">(struct redisCommand *cmd, <span class="hljs-keyword">int</span> dbid, robj **argv, <span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">int</span> flags)</span> </span>&#123;  <br> <span class="hljs-keyword">if</span> (server.aof_state != AOF_OFF &amp;&amp; flags &amp; PROPAGATE_AOF)  <br>     feedAppendOnlyFile(cmd,dbid,argv,argc);  <br>&#125; <br></code></pre></td></tr></table></figure><p>feedAppendOnlyFile()位于src/aof.c中，该函数将命令追加至aof_buf中，如果正在执行AOF重写，还需要将其追加到重写缓冲区中，具体实现过程包括以下四个步骤：</p><ol><li>使用 SELECT 命令，显式设置数据库，确保之后的命令被设置到正确的数据库；</li><li>将命令和命令参数还原为协议格式；</li><li>将命令追加到aof_buf中（使用函数sdscatlen()实现，该函数为Redis自定义的，针对sds结构实现的追加函数，位于src/sds.c中）；</li><li>如果BGREWRITEAOF正在进行，还需要将命令追加到重写缓存中（使用函数aofRewriteBufferAppend()实现，位于src/aof.c中）。</li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Append to the AOF buffer. This will be flushed on disk just before </span><br><span class="hljs-comment"> * of re-entering the event loop, so before the client will get a </span><br><span class="hljs-comment"> * positive reply about the operation performed. */</span>  <br><span class="hljs-keyword">if</span> (server.aof_state == AOF_ON)  <br>server.aof_buf = sdscatlen(server.aof_buf,buf,sdslen(buf));  <br><span class="hljs-comment">/* If a background append only file rewriting is in progress we want to </span><br><span class="hljs-comment"> * accumulate the differences between the child DB and the current one </span><br><span class="hljs-comment"> * in a buffer, so that when the child process will do its work we </span><br><span class="hljs-comment"> * can append the differences to the new append only file. */</span>  <br><span class="hljs-keyword">if</span> (server.aof_child_pid != <span class="hljs-number">-1</span>)  <br>aofRewriteBufferAppend((<span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span>*)buf,sdslen(buf));<br></code></pre></td></tr></table></figure><p>AOF文件的写入和同步采用的是src/aof.c/flushAppendOnlyFile函数。该函数在src/server.c/beforeSleep中会被调用，而beforeSleep函数是在处理client事件之前执行的（事件循环函数aeMain先执行beforesleep，然后执行aeProcessEvents），因此，server.aof_buf中的值会在向client发送响应之前刷新到磁盘上。</p><p>flushAppendOnlyFile(int force)函数的具体实现过程中，根据不同的同步策略以及后台是否有正在进行fsync操作，共分为以下几种情况：</p><ol><li>判断是否写入，同步策略为everysecond（server.aof_fsync == AOF_FSYNC_EVERYSEC），且没有要求强制写入（!force），且有fsync正在后台执行：<ul><li>之前没有推迟过write操作，则记录下时间，直接返回（如果此时强制执行write的话，服务器主线程将阻塞在write上面）；</li><li>之前推迟过write操作，但推迟时间&lt;2秒，直接返回；</li><li>推迟时间&gt;=2秒，不返回，继续执行。</li></ul></li><li>执行写入操作，调用aofWrite函数</li><li>判断是否同步：<ul><li>同步策略为always（server.aof_fsync == AOF_FSYNC_ALWAYS），执行同步操作（调用aof_fsync函数，在Linux系统，该函数使用fdatasync实现，在其他系统中，使用fsync实现）。</li><li>同步策略为everysecond，且距离上次写操作已超过1秒，且没有fsync在后台执行，则后台执行同步操作（调用aof_background_fsync函数）。</li></ul></li></ol><hr><h3 id="2-数据还原"><a href="#2-数据还原" class="headerlink" title="2 数据还原"></a>2 数据还原</h3><p>Redis启动之后，在src/server.c/main()函数中调用loadDataFromDisk()，当AOF为开启状态时，该函数会继续调用src/aof.c/loadAppendOnlyFile()，在该函数中会通过创建伪客户端的方式，遍历执行AOF文件的命令，还原数据库状态。</p><hr><h3 id="3-AOF重写"><a href="#3-AOF重写" class="headerlink" title="3 AOF重写"></a>3 AOF重写</h3><p>持续运行的Redis服务器需要定期对自身的资源和状态进行检查和调整，从而确保服务器可以长期、稳定地运行，这些定期操作由server.c/serverCron函数负责执行，它的主要工作包括：</p><ul><li>更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等；</li><li>清理数据库中的过期键值对；</li><li>关闭和清理连接失效的客户端；</li><li>触发BGSAVE或者AOF重写，并处理之后由BGSAVE和AOF重写引发的子进程停止。</li></ul><p>Redis服务器以周期性事件的方式来运行serverCron函数，在服务器运行期间，每秒调用server.hz次，直到服务器关闭为止。</p><h4 id="3-1-BGSAVE和BGREWRITEAOF的触发"><a href="#3-1-BGSAVE和BGREWRITEAOF的触发" class="headerlink" title="3.1 BGSAVE和BGREWRITEAOF的触发"></a>3.1 BGSAVE和BGREWRITEAOF的触发</h4><p>在serverCron()函数中与Redis持久化相关的检查以及处理流程如下图所示，具体实现包括：</p><p><img src="/img/article/Redis/image-20200607224305949.png" alt="serverCron中相关操作流程"></p><ul><li>如果BGSAVE和BGREWRITEAOF都没有在执行，但是有一个BGREWRITEAOF在等待（server.aof_rewrite_scheduled），那么执行BGREWRITEAOF（调用函数src/aof.c/rewriteAppendOnlyFileBackground）</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Start a scheduled AOF rewrite if this was requested by the user while </span><br><span class="hljs-comment"> * a BGSAVE was in progress. */</span>  <br><span class="hljs-keyword">if</span> (server.rdb_child_pid == <span class="hljs-number">-1</span> &amp;&amp; server.aof_child_pid == <span class="hljs-number">-1</span> &amp;&amp;  <br>server.aof_rewrite_scheduled) &#123;  <br>rewriteAppendOnlyFileBackground();  <br>&#125;  <br></code></pre></td></tr></table></figure><ul><li>如果BGSAVE和BGREWRITEAOF都没有在执行，而且也没有BGREWRITEAOF在等待，那么检查是否需要执行它们<ul><li>BGSAVE：检查m秒内是否发生了超过n次的变化（对应于配置文件中的save m n），BGSAVE操作由函数src/rdb.c/rdbSaveBackground实现</li><li>BGREWRITEAOF：<ul><li>当前AOF文件大小大于执行 BGREWRITEAOF 所需的最小大小，即server.aof_rewrite_min_size</li><li>当前AOF文件大小和最后一次重写后的大小之间的比率等于或者大于指定的增长百分比（auto-aof-rewrite-perc）</li></ul></li></ul></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Trigger an AOF rewrite if needed */</span>  <br><span class="hljs-keyword">if</span> (server.rdb_child_pid == <span class="hljs-number">-1</span> &amp;&amp; server.aof_child_pid == <span class="hljs-number">-1</span> &amp;&amp;  <br>    server.aof_rewrite_perc &amp;&amp;  <br>    server.aof_current_size &gt; server.aof_rewrite_min_size)  &#123;  <br>    <span class="hljs-comment">// 上一次完成 AOF 写入之后，AOF 文件的大小  </span><br><span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span> base = server.aof_rewrite_base_size ?  <br>                 server.aof_rewrite_base_size : <span class="hljs-number">1</span>;  <br><span class="hljs-comment">// AOF 文件当前的体积相对于 base 的体积的百分比  </span><br><span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span> growth = (server.aof_current_size*<span class="hljs-number">100</span>/base) - <span class="hljs-number">100</span>;  <br><span class="hljs-comment">// 如果增长体积的百分比超过了 growth ，那么执行 BGREWRITEAOF  </span><br><span class="hljs-keyword">if</span> (growth &gt;= server.aof_rewrite_perc) &#123; <br>    rewriteAppendOnlyFileBackground();  <br>&#125;  <br>&#125;  <br></code></pre></td></tr></table></figure><ul><li>如果存在BGSAVE或者BGREWRITEAOF在执行，则检查其是否已经执行完毕，并处理因此而引发的子进程停止</li><li>如果服务器开启了AOF持久化功能，并且AOF缓冲区里面还有待写人的数据，那么serverCron会调用相应的程序，将AOF缓冲区中的内容写入到AOF文件里面</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* AOF postponed flush: Try at every cron cycle if the slow fsync </span><br><span class="hljs-comment"> * completed. */</span>  <br><span class="hljs-keyword">if</span> (server.aof_flush_postponed_start)   <br> flushAppendOnlyFile(<span class="hljs-number">0</span>);  <br></code></pre></td></tr></table></figure><p>在serverCron函数中会通过检查BGREWRITEAOF的两个自动触发条件来执行AOF重写，但除此之外，用户还可以通过在客户端输入bgwriteaof命令来手动触发AOF重写。与其他命令的处理流程相同，bgwriteaof命令对应的命令处理函数为aof.c/bgrewriteaofCommand()：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">bgrewriteaofCommand</span><span class="hljs-params">(client *c)</span> </span>&#123;  <br>    <span class="hljs-keyword">if</span> (server.aof_child_pid != <span class="hljs-number">-1</span>) &#123;  <br>        addReplyError(c,<span class="hljs-string">&quot;Background AOF rewriting already in progress&quot;</span>);  <br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (server.rdb_child_pid != <span class="hljs-number">-1</span>) &#123;  <br>    server.aof_rewrite_scheduled = <span class="hljs-number">1</span>;  <br>    addReplyStatus(c,<span class="hljs-string">&quot;Background append only file rewriting scheduled&quot;</span>);<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (rewriteAppendOnlyFileBackground() == C_OK) &#123;  <br>    addReplyStatus(c,<span class="hljs-string">&quot;Background append only file rewriting started&quot;</span>); <br>&#125; <span class="hljs-keyword">else</span> &#123;  <br>    addReply(c,shared.err);  <br>&#125;  <br>&#125;  <br></code></pre></td></tr></table></figure><p>在该函数中，AOF重写也是通过调用rewriteAppendOnlyFileBackground函数来实现的。但当有BGSAVE在执行时（server.rdb_child_pid != -1），BGREWRITEAOF会等待（server.aof_rewrite_scheduled = 1），如前文所述，等待的BGREWRITEAOF会在serverCron函数中被执行。</p><h4 id="3-2-AOF重写的实现"><a href="#3-2-AOF重写的实现" class="headerlink" title="3.2 AOF重写的实现"></a>3.2 AOF重写的实现</h4><p>AOF重写是依靠rewriteAppendOnlyFileBackground函数实现的，该函数的处理过程包括：</p><ol><li>使用fork创建一个子进程；</li><li>子进程调用aof.c/rewriteAppendOnlyFile函数在一个临时文件里写入能够反映当前db状态的数据和命令，此时父进程会把这段时间内执行的能够改变当前db数据的命令放到重写缓冲区中；</li><li>当子进程退出时，父进程收到信号，将上面的重写缓冲区中的数据flush到临时文件中，然后将临时文件rename成新的aof文件。</li></ol><p>子进程调用rewriteAppendOnlyFile函数后，在该函数中会继续调用实际的重写函数aof.c/rewriteAppendOnlyFileRio，该函数遍历db中的每条数据，取出键，取出值，然后根据值的类型选择适当的命令来进行保存，然后写入并同步AOF临时文件中。</p><p>在serverCron函数中，会周期性的检查BGREWRITEAOF子进程是否已退出，当父进程收到退出信号后，会调用aof.c/backgroundRewriteDoneHandler函数完成后续处理，包括：</p><ol><li>调用aof.c/aofRewriteBufferWrite函数，将累计的AOF重写缓冲区的内容追加到AOF临时文件中；</li><li>将AOF 临时文件rename，替换现有的AOF文件。</li></ol><p>参考内容：《Redis设计与实现》，黄健宏著</p>]]></content>
    
    
    <categories>
      
      <category>Redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>持久化</tag>
      
      <tag>AOF</tag>
      
      <tag>源码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[Redis] Redis的数据持久化机制</title>
    <link href="/2021/07/04/Redis-AOF-RDB/"/>
    <url>/2021/07/04/Redis-AOF-RDB/</url>
    
    <content type="html"><![CDATA[<p>Redis作为一种高性能的内存数据库，将全部数据储存在内存当中，因此一旦发生服务器宕机或系统崩溃，存储的数据就会全部丢失。为了解决这一问题，Redis提供RDB和AOF两种持久化机制，将数据同步到磁盘中。当系统或服务器重启时，利用持久化文件即可恢复数据，有效的避免了数据丢失问题。</p><span id="more"></span><hr><h3 id="1-RDB持久化"><a href="#1-RDB持久化" class="headerlink" title="1 RDB持久化"></a>1 RDB持久化</h3><p>RDB持久化方式是通过快照（snapshotting）完成的，当符合一定条件时，redis会自动将内存中所有数据以二进制方式生成一份副本并存储在硬盘上。当redis重启时，redis会读取RDB持久化生成的二进制文件进行数据恢复。</p><h4 id="1-1-RDB持久化的触发条件"><a href="#1-1-RDB持久化的触发条件" class="headerlink" title="1.1 RDB持久化的触发条件"></a>1.1 RDB持久化的触发条件</h4><h5 id="手动触发"><a href="#手动触发" class="headerlink" title="手动触发"></a>手动触发</h5><ul><li><p>save命令触发</p><p>客户端执行save命令，该命令强制redis执行快照，这时候redis处于阻塞状态，不会响应任何其他客户端发来的请求，直到RDB快照文件执行完毕，所以请慎用。</p></li><li><p>bgsave命令触发</p><p>bgsave，即后台保存，当执行bgsave命令时，redis会fork出一个子进程来执行快照生成操作，需要注意的redis是在fork子进程这个简短的时间redis是阻塞的，当子进程创建完成以后redis继续响应客户端请求。执行过程如下图所示：</p></li></ul><p><img src="/img/article/Redis/RDB%E6%8C%81%E4%B9%85%E5%8C%96bgsave%E8%BF%87%E7%A8%8B.jpg" alt="RDB持久化bgsave过程"></p><h5 id="自动触发"><a href="#自动触发" class="headerlink" title="自动触发"></a>自动触发</h5><p>自动触发最常见的情况是在配置文件中通过save m n，指定当m秒内发生n次变化时，会触发bgsave。</p><p>自动触发实际是在Redis内部一个定时器事件，每隔固定时间去检查当前数据发生的改变次数与时间是否满足配置的持久化触发的条件，如果满足则通过操作系统fork调用来创建出一个子进程，这个子进程默认会与父进程共享相同的地址空间，这时就可以通过子进程来遍历整个内存来进行存储操作，而主进程则仍然可以提供服务，当有写入时由操作系统按照内存页(page)为单位来进行copy-on-write保证父子进程之间不会互相影响。</p><p>除了save m n以外，还有一些其他情况会触发bgsave， 在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点。执行shutdown命令时，也会自动执行rdb持久化。</p><h4 id="1-2-RDB持久化的优缺点"><a href="#1-2-RDB持久化的优缺点" class="headerlink" title="1.2 RDB持久化的优缺点"></a>1.2 RDB持久化的优缺点</h4><ul><li>优点：<ol><li>RDB是一个非常紧凑的文件，体积小，易于传输，适合灾难恢复。</li><li>RDB可以最大化Redis的性能：父进程在保存RDB文件时唯一要做的就是fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘I/O操作。</li><li>RDB在恢复大数据集时的速度比AOF的恢复速度要快。</li></ol></li><li>缺点：<ol><li>RDB是一个快照过程，无法完整的保存所以数据，尤其在数据量比较大时候，一旦出现故障丢失的数据将更多。</li><li>RDB需要fork子进程将内容持久化在磁盘上。如果数据集很大，fork可能很耗时，并且如果数据集很大且CPU性能不佳，则可能导致Redis停止服务几毫秒甚至一秒钟。AOF机制也需要fork，但可以调整重写日志的频率。</li></ol></li></ul><hr><h3 id="2-AOF持久化"><a href="#2-AOF持久化" class="headerlink" title="2 AOF持久化"></a>2 AOF持久化</h3><p>除了RDB持久化功能外，Redis还提供了AOF持久化功能。与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF持久化是通过保存Redis服务器所执行的写命令来记录数据库状态的。</p><h4 id="2-1-AOF持久化的实现"><a href="#2-1-AOF持久化的实现" class="headerlink" title="2.1 AOF持久化的实现"></a>2.1 AOF持久化的实现</h4><p>AOF 持久化功能的实现可以分为命令追加，文件写入，文件同步三个步骤。</p><h5 id="命令追加"><a href="#命令追加" class="headerlink" title="命令追加"></a>命令追加</h5><p>当AOF持久化功能处于打开状态时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾。其中aof_buf的定义位于redisServer结构体中。</p><h5 id="AOF文件的同步和写入"><a href="#AOF文件的同步和写入" class="headerlink" title="AOF文件的同步和写入"></a>AOF文件的同步和写入</h5><p>因为服务器在处理文件事件时可能会执行写命令，使得一些内容被追加到aof_buf缓冲区里，所以在服务器每次结束一个事件循环之前，他都会调用flushAppendOnlyFile函数，考虑是否需要将aof_buf缓冲区中的内容写入和同步到AOF文件中。</p><p>针对flushAppendOnlyFile函数的行为，redis提供了三种同步策略，由配置参数appendfsync来决定，各个不同值产生的行为如下所示：</p><ul><li>everysec：将aof_buf 缓冲区中的所有内容写入到AOF 文件，如果上次同步AOF 文件的时间距离现在超过一秒钟，那么再次对AOF 文件进行同步，并且这个同步操作是由一个专门负责执行的。</li><li>always：将aof_buf 缓冲区的所有内容写入并同步到AOF 文件中。</li><li>no：将aof_buf 缓冲区的所有内容写入到AOF 文件中，但并不对AOF 文件进行同步，合适同步由操作系统决定。</li></ul><p>从效率上来讲，everysec模式足够快，并且就算出现故障停机，数据库也只丢失1秒的命令数据。这是折中的方案，兼顾性能和数据安全，也是redis的默认配置。</p><p>always模式在每次写操作后都调用fsync方法强制内核将数据写入到aof文件。这种情况下虽然数据比较安全，但是因为每次写操作都会同步到AOF文件中，所以在性能上会有影响，同时由于频繁的IO操作，硬盘的使用寿命会降低。</p><p>no模式下的同步交给操作系统write函数去执行，这种情况下，AOF文件写入速度是最快的，不过因为这种模式会在系统缓存中积累一段时间的写入数据，所以该模式的单次同步时长通常是三种模式中时间最长的。从平摊操作的角度来看，no模式和everysec模式的效率类似，当出现故障停机时，使用no模式的服务器将丢失上次同步AOF文件之后的所有写命令数据。</p><h4 id="2-2-AOF文件的载入与数据还原"><a href="#2-2-AOF文件的载入与数据还原" class="headerlink" title="2.2 AOF文件的载入与数据还原"></a>2.2 AOF文件的载入与数据还原</h4><p>因为AOF文件里面包含了重建数据库状态所需的所有写命令，所以服务器只要读入并重新执行一遍AOF文件里面保存的写命令，就可以还原服务器关闭之前的数据库状态。Redis读取AOF文件并还原数据库的详细步骤如下图所示。</p><p><img src="/img/article/Redis/AOF%E6%96%87%E4%BB%B6%E8%BD%BD%E5%85%A5%E8%BF%87%E7%A8%8B.jpg" alt="AOF文件载入过程"></p><p>因为Redis的命令只能在客户端上下文中执行，而载入AOF文件时所使用的命令直接来源于AOF文件而不是网络连接，所以服务器使用了一个没有网络连接的伪客户端来执行AOF文件保存的写命令，伪客户端执行命令的效果和网络连接的客户端执行命令的效果完全一样。</p><h4 id="2-3-AOF重写"><a href="#2-3-AOF重写" class="headerlink" title="2.3 AOF重写"></a>2.3 AOF重写</h4><p>因为AOF持久化是通过保存被执行的写命令来记录数据库状态的，所以随着服务器运行时间的流逝，AOF文件中的内容会越来越多，文件的体积也会越来越大，体积过大的AOF文件很可能对Redis服务器、甚至整个宿主计算机造成影响，同时使用AOF文件来进行数据还原所需的时间也越多。</p><p>为了解决AOF文件体积膨胀的问题，Redis提供了AOF文件重写(rewrite)功能。通过该功能，Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个AOF文件所保存的数据库状态相同，但新AOF文件不会包含任何浪费空间的冗余命令，所以新AOF文件的体积通常会比旧AOF文件的体积要小得多。</p><h5 id="AOF文件重写的实现"><a href="#AOF文件重写的实现" class="headerlink" title="AOF文件重写的实现"></a>AOF文件重写的实现</h5><p>AOF文件重写并不需要对现有的AOF文件进行任何读取、分析或者写入操作，这个功能是通过读取服务器当前的数据库状态来实现的。</p><p>假设服务器对某一个key执行了多个写命令，那么服务器为了保存该key的当前状态，必须将这些写命令全部写入AOF文件中。如果服务器想要用尽量少的命令来记录该key的状态，最简单高效的办法不是去读取和分析现有AOF文件的内容，而是直接从数据库中读取该key对应的value值，然后用一条写命令命令来代替原有的多个写命令即可，这就是AOF重写功能的实现原理。</p><p>在实际中，为了避免在执行命令时造成客户端输入缓冲区溢出，重写程序在处理列表、哈希表、集合、有序集合这四种可能会带有多个元素的键时，会先检查键所包含的元素数量，如果元素的数量超过了AOF_REWRITE_ITEMS_PER_CMD常量的值，那么重写程序将使用多条命令来记录键的值，而不单单使用一条命令。在Redis4.0版本中，AOF_REWRITE_ITEMS_PER_CMD常量的值为64。</p><h5 id="AOF后台重写"><a href="#AOF后台重写" class="headerlink" title="AOF后台重写"></a>AOF后台重写</h5><p>因为Redis服务器使用单个线程来处理命令请求，所以如果由服务器直接调用AOF重写函数的话，那么在重写期间，服务期将无法处理客户端发来的命令请求，所以Redis决定将AOF重写程序放到子进程里执行，这样做可以同时达到两个目的：</p><ul><li>子进程进行AOF重写期间，服务器进程可以继续处理命令请求。</li><li>子进程带有服务器进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性。</li></ul><p>但子进程在进行AOF重写期间，服务器进程还需要继续处理命令请求，而新的命令可能会对现有的数据库状态进行修改，从而使得服务器当前的数据库状态和重写后的AOF文件所保存的数据库状态不一致。为了解决这种数据不一致问题，Redis服务器设置了一个AOF重写缓冲区（aof_rewrite_buf），这个缓冲区在服务器创建子进程之后开始使用，当Redis服务器执行完一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区。</p><p>AOF文件触发条件可分为手动触发和自动触发：</p><ul><li>手动触发：客户端执行bgrewriteaof命令。</li><li>自动触发：自动触发通过以下两个配置协作生效：<ol><li>uto-aof-rewrite-min-size: AOF文件最小重写大小，只有当AOF文件大小大于该值时候才可能重写，4.0默认配置64MB。</li><li>auto-aof-rewrite-percentage：当前AOF文件大小和最后一次重写后的大小之间的比率等于或者等于指定的增长百分比，如100代表当前AOF文件是上次重写的两倍时候才重写。</li></ol></li></ul><p>每次当serverCron（服务器周期性操作函数）函数执行时，它会检查以下条件是否全部满足，如果全部满足的话，就触发自动的AOF重写操作：</p><ul><li>没有BGSAVE命令（RDB持久化）/AOF持久化在执行；</li><li>没有BGREWRITEAOF在进行；</li><li>当前AOF文件大小要大于server.aof_rewrite_min_size的值；</li><li>当前AOF文件大小和最后一次重写后的大小之间的比率等于或者大于指定的增长百分比（auto-aof-rewrite-perc）<br>整个AOF后台重写过程如下所示：</li></ul><p><img src="/img/article/Redis/AOF%E5%90%8E%E5%8F%B0%E9%87%8D%E5%86%99%E8%BF%87%E7%A8%8B.jpg" alt="AOF后台重写过程"></p><ol><li>开始bgrewriteaof</li><li>主进程fork出子进程，在这一个短暂的时间内，redis是阻塞的。</li><li>主进程fork完子进程继续接受客户端请求，此时，客户端的写请求不仅仅写入原来aof_buf缓冲，还写入重写缓冲区aof_rewrite_buf。</li><li>子进程通过内存快照，按照命令重写策略写入到新的AOF文件。<ul><li>子进程写完新的AOF文件后，向主进程发信号。</li><li>主进程把aof_rewrite_buf中的数据写入到新的AOF文件。</li></ul></li><li>对新的AOF文件进行改名，原子的覆盖现有的AOF文件，完成新旧两个AOF文件的替换。</li></ol><h4 id="2-4-AOF持久化的优缺点"><a href="#2-4-AOF持久化的优缺点" class="headerlink" title="2.4 AOF持久化的优缺点"></a>2.4 AOF持久化的优缺点</h4><ul><li>优点：<ol><li> 更高的数据安全性，同时有不同的同步策略</li><li> AOF包含一个格式清晰、易于理解的日志文件记录所有的修改操作。</li><li> AOF机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。同时Redis还提供redis-check-aof工具来解决数据一致性的问题。</li></ol></li><li>缺点：<ol><li> 数据文件体积较大，即使有重写机制，但是在相同的数据集情况下，AOF文件通常比RDB文件大。</li><li> 相对RDB方式，AOF模式的恢复速度慢于RDB。</li><li> 由于频繁地将命令同步到文件中，AOF持久化对性能的影响相对RDB较大，但仍在一个可以接受的范围内。</li></ol></li></ul><hr><h3 id="3-RDB-AOF混合持久化"><a href="#3-RDB-AOF混合持久化" class="headerlink" title="3 RDB-AOF混合持久化"></a>3 RDB-AOF混合持久化</h3><p>从redis4.0开始，添加了新的混合持久化方式，这里介绍的混合持久化就是同时结合RDB持久化以及AOF持久化混合写入AOF文件。这样做的好处是可以结合RDB和AOF的优点，快速加载同时避免丢失过多的数据，缺点是AOF里面的RDB部分就是压缩格式不再是AOF格式，可读性差。</p><p>混合持久化同样也是通过bgrewriteAOF完成的，不同的是当开启混合持久化时，fork出的子进程先将共享的内存副本全量的以RDB方式写入AOF文件，然后在将重写缓冲区的增量命令以AOF方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的的AOF文件。简单的说，新的AOF文件前半段是RDB格式的全量数据，后半段是AOF格式的增量数据。</p><p>当我们开启了混合持久化时，启动redis依然优先加载AOF文件，AOF文件加载可能有两种情况如下：</p><ul><li>AOF文件开头是RDB的格式，先加载RDB内容再加载剩余的AOF。</li><li>AOF文件开头不是RDB的格式，直接以AOF格式加载整个文件。</li></ul><p>参考内容：<br>[1]《redis系列–redis4.0深入持久化》，<a href="https://www.cnblogs.com/wdliu/p/9377278.html">https://www.cnblogs.com/wdliu/p/9377278.html</a><br>[2]《Redis设计与实现》，黄健宏著</p>]]></content>
    
    
    <categories>
      
      <category>Redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>持久化</tag>
      
      <tag>RDB</tag>
      
      <tag>AOF</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[Paper] Pangolin: A Fault-Tolerant Persistent Memory Programming Library</title>
    <link href="/2021/07/03/Pangolin/"/>
    <url>/2021/07/03/Pangolin/</url>
    
    <content type="html"><![CDATA[<p>论文发表于2019年USENIX Annual Technical Conference(ATC)中，提出了一种能实现fault tolerance的，基于DAX-map的NVMM编程库——Pangolin。论文出自加州大学圣地亚哥分校的Non-Volatile Systems Laboratory(NVSL)。该实验室专注于新型内存技术的研究，近年来在ATC、FAST、ASPLOS等A类会议发表多篇高水平论文，包括基于非易失性内存的测试框架、文件系统、编程库等多个方向。</p><p>非易失性内存(NVMM)的一个重要特征就是支持DAX模式，在该模式下，实现崩溃一致性(Crash consistency)和容错(Fault tolerance)都十分必要，近年来已经有诸多实验团队针对Crash consistency提出解决方法，但对于Fault tolerance的研究还比较稀少。在这样的背景下，论文提出了一种能实现fault tolerance的，基于DAX-map的NVMM编程库——Pangolin，用于应用程序在NVMM中构建复杂的数据结构。Pangolin结合了校验和(checksum)、奇偶校验(parity)和微缓冲(micro-buffer)三种技术，能够同时避免media error和software bug带来的损害，并支持自动检测和在线恢复。与现阶段支持fault tolerance的NVMM编程库相比，Pangolin使用了的很小的存储开销，达到了类似的性能。</p><p>现阶段的NVM编程库libpmemobj通过副本(replication)的方法来实现fault tolerance，但这样会带来100%的空间开销，为了减少存储开销，Pangolin提出了下图所示的数据保护模式：</p><p><img src="/img/article/Paper/1.png"></p><p>对于一个NVMM pool，其中pool和zone的元数据PM和ZM，以及Log区域仍然采用replication的方式进行容错，因为这一部分所占的存储空间很小（对于1GB的pool，只占用0.1%的存储空间）。对于chunk区域，在逻辑上将其组织为二维数组的形式，最后一行作为parity data进行奇偶检验，chunk的元数据CM和object data都通过parity来进行数据容错。同时，Pangolin还在每个object header中开辟了32 bit的区域存放checksum，进行object data的错误检测。</p><p>为了降低更新checksum和parity所带来的的一致性挑战，Pangolin引入了micro-buffer。当需要修改一个PMEM中的object时，需要在micro-buffer中做一个object的shadow copy，对object的修改将在DRAM中进行，修改完成后重新计算checksum，将checksum和修改操作记录到Log中，随后进行parity的更新操作，当以上步骤都完成以后，将修改后的object写回PMEM中。一次完整的流程如下图所示：</p><p><img src="/img/article/Paper/2.png"></p><p>采用micro-buffer除了可以降低更新一致性的复杂性以外，还可以避免缓冲区溢出，悬垂指针等软件bug对NVMM带来的影响。同时，由于micro-buffer位于DRAM中，可以借鉴一些内存调试工具的思想来实现更强的数据保护，例如，Pangolin在每个micro-buffer的header中插入了一个64-bit的canary，在将object写回之前，通过验证其完整性提供对NVMM的保护。</p><p>由于XOR运算的可交换性，在进行parity更新时，可以实现较为简单的增量更新，单个object的修改带来的parity更新过程如下图所示：</p><p><img src="/img/article/Paper/3.png"></p><p>当一个Range Column中的多个object同时进行更新时，就带来了parity update的一致性挑战，同时由于Atomic XOR要慢于Vectorized XOR，为了保证更新一致性同时兼顾计算效率，论文引入了一种细粒度锁——parity range-locks。对于Small updates (&lt; 8KB)，共享range-lock，采用atomic XOR instructions并行更新parity；对于Large updates (≥ 8KB)，独占range-lock，采用Vectorized XOR串行更新parity。</p><p>与libpmemobj的replication方式相比，Pangolin使用更小的存储空间实现了类似的性能，同时保证了crash consistency，除此之外还支持software级别的错误检测和在线恢复。但在容错度方面，Pangolin仅支持任意位置的单4KB page的错误，或者位于不同Range Column的object错误，这是由parity本身的性质导致的，为了提高容错度，就需要减少行数，增加列数以减少错误overlap的概率，但过多的列数同样会增加计算parity的开销。除此之外，Pangolin仅支持多线程同时修改不同的object，不支持多线程同时修改同一个object，这同时也是libpmemobj存在的问题。</p><p>论文链接：<a href="https://www.usenix.org/conference/atc19/presentation/zhang-lu">https://www.usenix.org/conference/atc19/presentation/zhang-lu</a></p>]]></content>
    
    
    <categories>
      
      <category>paper</category>
      
    </categories>
    
    
    <tags>
      
      <tag>容错</tag>
      
      <tag>PM</tag>
      
      <tag>NVM</tag>
      
      <tag>PMDK</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2021/07/03/hello-world/"/>
    <url>/2021/07/03/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
